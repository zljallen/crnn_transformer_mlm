{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acc5217-ce5c-4a03-99ef-3a6afe6bf471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from DL_ClassifierModel import *\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os,torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d532c1b9-9384-47a2-a3f0-41fd62d2771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f16328b-d7c8-4d0b-8c19-d5488c894cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "dataClass = DataClass_multi_output('../DataSet/', 'Data/train.txt', 'Data/test.txt', 'Data/vocabulary_agnostic.txt', hs=128, dropBLANK=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae767ea-b0fa-44eb-a1ad-6020bd587640",
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立模型\n",
    "model = Trans2trans_multi_output(   classNum1=dataClass.classNum1, classNum2=dataClass.classNum2, \n",
    "                                    labType2id=dataClass.labType2id, id2labType=dataClass.id2labType, labLoc2id=dataClass.labLoc2id,                                                     id2labLoc=dataClass.id2labLoc, \n",
    "                                    lab12id=dataClass.lab12id, id2lab1=dataClass.id2lab1,\n",
    "                                    seqMaxLen=dataClass.maxItems*4+1+dataClass.maxItems+1,\n",
    "                                    tknDropout=0.1, embDropout=0.0, hdnDropout=0.1, fcDropout=0.0,\n",
    "                                    imgHeight=128, contextSizeList=[1,5,25,49], feaSize=1024, rnnLayerNum=2,\n",
    "                                    transNum=4, dk=48, multiNum=8, usePos=True, usePreLN=True,\n",
    "                                    maxItems=dataClass.maxItems, device=torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bbad6e-f67b-4941-bfde-4cffbfffd0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load('TrainModel_splitAgnostic.pkl', map_location=\"cuda\")\n",
    "model.to_eval_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fdd0f3-d053-4af8-9e67-62570528299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#选取一批数据\n",
    "def batch_image_predict(batchImgArr):\n",
    "    bs = len(batchImgArr)\n",
    "    imgArr = torch.tensor(batchImgArr, dtype=torch.float32, device=model.device).transpose(1,2)\n",
    "    imgLab = torch.cat([torch.tensor([[[2,2]]]*bs,device=model.device),torch.zeros((bs,model.maxItems+1,2), dtype=torch.long, device=model.device)], dim=1)\n",
    "    imgLab_type = torch.cat([torch.tensor([[2]],device=model.device),torch.zeros((1,model.maxItems+1), dtype=torch.long, device=model.device)], dim=1)\n",
    "    imgLab_loc = torch.cat([torch.tensor([[2]],device=model.device),torch.zeros((1,model.maxItems+1), dtype=torch.long, device=model.device)], dim=1)\n",
    "    cnt = 1\n",
    "    x = torch.cat(model.seqCNN(imgArr), dim=-1)\n",
    "    x_pool = F.adaptive_max_pool1d(x.transpose(1,2), model.maxItems*4).transpose(1,2)\n",
    "    while True:\n",
    "        imgLab_type = imgLab[:,:,0]\n",
    "        imgLab_loc = imgLab[:,:,1]\n",
    "        \n",
    "        y1 = model.symEmbedding1(imgLab_type)\n",
    "        y2 = model.symEmbedding2(imgLab_loc)\n",
    "        y = y1 + y2\n",
    "        # x_pool: 1 × seqLen × feaSize\n",
    "        B,L,C = x_pool.shape\n",
    "        x_rnn, hn = model.eSeqRNN(torch.cat([x_pool,y[:,:1]], dim=1)) # => batchSize × seqLen × hiddenSize*2\n",
    "        eos = x_rnn[:,-1:]\n",
    "        x_rnn = x_rnn[:,:-1]\n",
    "        x = x_rnn + x_pool\n",
    "        x = torch.cat([x, eos], dim=1)\n",
    "        if type(hn)==tuple:\n",
    "            hn,cn = hn\n",
    "            hn = hn.view(model.rnnLayerNum, 2, B, C//2)\n",
    "            hn = torch.cat([hn[:,0],hn[:,1]], dim=2) # => numLayers × batchSize × hiddenSize*2\n",
    "            cn = hn.view(model.rnnLayerNum, 2, B, C//2)\n",
    "            cn = torch.cat([cn[:,0],cn[:,1]], dim=2) # => numLayers × batchSize × hiddenSize*2\n",
    "            hn = (hn,cn)\n",
    "        else:\n",
    "            hn = hn.view(model.rnnLayerNum, 2, B, C//2)\n",
    "            hn = torch.cat([hn[:,0],hn[:,1]], dim=2) # => numLayers × batchSize × hiddenSize*2x = torch.cat([x, eos], dim=1)\n",
    "        y, _ = model.dSeqRNN(y[:,1:], h0=hn) # => batchSize × seqLen × hiddenSize*2\n",
    "        x = torch.cat([x,y], dim=1) # => batchSize × (seqLen+1+maxItems+1) × feaSize\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            x,_ = nn.parallel.data_parallel(model.transformer,x)\n",
    "        else:\n",
    "            x,_ = model.transformer(x) # => batchSize × (seqLen+1+maxItems+1) × feaSize\n",
    "        y = x[:,-model.maxItems-2:-1]\n",
    "        y = model.fcLinear(F.relu(y)) # => 1 × (maxItems+1) × classNum\n",
    "        \n",
    "        yp1,yp2 = y[:,:,:model.classNum1],y[:,:,model.classNum1:]\n",
    "        \n",
    "        \n",
    "        y = torch.cat([torch.tensor([[[2,2]]]*bs, device=model.device),torch.cat([yp1.argmax(dim=-1,keepdim=True),yp2.argmax(dim=-1,keepdim=True)],dim=-1)], dim=1) # => 1 × (maxItems+1)\n",
    "\n",
    "        imgLab = torch.tensor(y, dtype=torch.long, device=model.device)\n",
    "\n",
    "        if cnt>model.maxItems:\n",
    "            break\n",
    "        cnt += 1    \n",
    "    Y_pre = imgLab\n",
    "    Y_pre = [[(model.id2labType[j[0]]+'-'+model.id2labLoc[j[1]]).replace('<EOS>-<EOS>', '<EOS>').replace('<PAD>-<PAD>', '<PAD>').replace('<SOS>-<SOS>', '<SOS>') for j in i] for i in Y_pre]\n",
    "    Y_pre = np.array([[model.lab12id[j] if j in model.lab12id else -1 for j in i] for i in Y_pre], dtype='int32')\n",
    "    \n",
    "    return Y_pre.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3924d78-94b4-4fb2-b84e-ab12353902f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#预测值\n",
    "bs = 64\n",
    "ypreList = []\n",
    "for i in tqdm(range((len(dataClass.testIdList)+bs-1)//(bs))):\n",
    "    samples = dataClass.testIdList[i*bs:(i+1)*bs]\n",
    "    imgArr = dataClass.imgArr[samples]-0.5\n",
    "    yps = batch_image_predict(imgArr)\n",
    "    for yp in yps:\n",
    "        ypreList.append(yp[:yp.index(1)] if 1 in yp else yp)\n",
    "\n",
    "\n",
    "#实际值\n",
    "yList = []\n",
    "for i in dataClass.testIdList:\n",
    "    y = dataClass.labArr[i].tolist()\n",
    "    yList.append(y[:y.index(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216edbb2-13a7-498e-b618-3cb70cd13d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein(a,b):\n",
    "    \"Computes the Levenshtein distance between a and b.\"\n",
    "    n, m = len(a), len(b)\n",
    "\n",
    "    if n > m:\n",
    "        a,b = b,a\n",
    "        n,m = m,n\n",
    "\n",
    "    current = range(n+1)\n",
    "    for i in range(1,m+1):\n",
    "        previous, current = current, [i]+[0]*n\n",
    "        for j in range(1,n+1):\n",
    "            add, delete = previous[j]+1, current[j-1]+1\n",
    "            change = previous[j-1]\n",
    "            if a[j-1] != b[i-1]:\n",
    "                change = change + 1\n",
    "            current[j] = min(add, delete, change)\n",
    "\n",
    "    return current[n]\n",
    "\n",
    "def edit_distance(a,b,EOS=1,PAD=1):\n",
    "    _a = [s for s in a if s != EOS and s != PAD]\n",
    "    _b = [s for s in b if s != EOS and s != PAD]\n",
    "\n",
    "    return levenshtein(_a,_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9c39d7-6691-453b-a54d-48fb9bbba0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seqErrorDivSeq(Y_pre, Y):\n",
    "    seqError = 0\n",
    "    for yp, yt in zip(Y_pre, Y):\n",
    "        l = len(yt)\n",
    "        i1,i2 = yp.index(1) if 1 in yp else l,yt.index(1) if 1 in yt else l\n",
    "        yp,yt = yp[:i1],yt[:i2]\n",
    "        if len(yp)==l:\n",
    "            if yp==yt:\n",
    "                seqError += 1\n",
    "    print(seqError, len(Y))\n",
    "    return 1-seqError / len(Y)\n",
    "def editDistDivSeq(Y_pre, Y):\n",
    "    editDist = 0\n",
    "    for yp, yt in zip(Y_pre, Y):\n",
    "        l = len(yt)\n",
    "        i1,i2 = min(yp.index(1) if 1 in yp else l, yp.index(0) if 0 in yp else l),min(yt.index(1) if 1 in yt else l,yt.index(0) if 0 in yt else l)\n",
    "        yp,yt = yp[:i1],yt[:i2]\n",
    "        editDist += edit_distance(yp, yt)\n",
    "    print(editDist, len(Y))\n",
    "    return editDist / len(Y)\n",
    "def editDistDivSymbol(Y_pre, Y):\n",
    "    editDist = 0\n",
    "    allSymbol = 0\n",
    "    for yp, yt in zip(Y_pre, Y):\n",
    "        l = len(yt)\n",
    "        i1,i2 = min(yp.index(1) if 1 in yp else l, yp.index(0) if 0 in yp else l),min(yt.index(1) if 1 in yt else l,yt.index(0) if 0 in yt else l)\n",
    "        yp,yt = yp[:i1],yt[:i2]\n",
    "        editDist += edit_distance(yp, yt)\n",
    "        allSymbol += len(yt)\n",
    "    print(editDist, allSymbol)\n",
    "    return editDist / allSymbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a58196-c34c-469f-8bc2-bb22607295cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( seqErrorDivSeq(ypreList, yList) )\n",
    "print( editDistDivSeq(ypreList, yList) )\n",
    "print( editDistDivSymbol(ypreList, yList) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
